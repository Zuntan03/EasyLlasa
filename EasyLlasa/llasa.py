import argparse
import gc
import logging
import os
import re
import subprocess
import time
import warnings
from datetime import datetime
from typing import Optional, Tuple

import pywintypes
import win32file
import win32pipe

# ç‰¹å®šã®è­¦å‘Šã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§æŠ‘åˆ¶
warnings.filterwarnings("ignore", message="pkg_resources is deprecated", category=UserWarning)

# PyTorchã®åˆ†æ•£å‡¦ç†è­¦å‘Šã‚’æŠ‘åˆ¶ï¼ˆãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ çµŒç”±ï¼‰
logging.getLogger("torch.distributed.elastic.multiprocessing.redirects").setLevel(logging.ERROR)

import numpy as np
import soundfile as sf
import torch
import torchaudio
from faster_whisper import WhisperModel
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from xcodec2.modeling_xcodec2 import XCodec2Model


class Llasa:
    """
    Llasa voice generation tool / LlasaéŸ³å£°ç”Ÿæˆãƒ„ãƒ¼ãƒ«

    Performance optimizations / ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–:
    - Use faster-whisper for speech recognition (automatic) / éŸ³å£°èªè­˜ã«faster-whisperã‚’ä½¿ç”¨ï¼ˆè‡ªå‹•ï¼‰
    - SageAttention is automatically detected and enabled if available / SageAttentionã¯åˆ©ç”¨å¯èƒ½ãªå ´åˆè‡ªå‹•æ¤œå‡ºãƒ»æœ‰åŠ¹åŒ–
    - Use --quantization to enable 4-bit quantization for VRAM efficiency / --quantizationã§4bité‡å­åŒ–ã‚’æœ‰åŠ¹åŒ–ã—VRAMåŠ¹ç‡åŒ–
    """

    def __init__(self):
        self.model = None
        self.batch_count = 0
        self.quantization_enabled = False  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é‡å­åŒ–ç„¡åŠ¹
        self.seed = None  # ãƒ†ã‚¹ãƒˆç”¨ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆå†ç¾æ€§ç¢ºä¿ã®ãŸã‚ï¼‰
        self.paths = []
        self.play_audio = False  # éŸ³å£°å†ç”Ÿãƒ•ãƒ©ã‚°
        self.volume = 1.0  # éŸ³å£°å†ç”ŸéŸ³é‡
        self.speed = 1.0  # éŸ³å£°å†ç”Ÿé€Ÿåº¦
        self.ffplay_process = None  # å‰å›ã®å†ç”Ÿãƒ—ãƒ­ã‚»ã‚¹

        # ãƒ¢ãƒ‡ãƒ«é–¢é€£ã®å±æ€§
        self.llasa_model = None
        self.tokenizer = None
        self.codec_model = None
        self.whisper_model = None

        # æ™‚é–“è¨ˆæ¸¬ç”¨ã®å±æ€§
        self.generation_start_time = None
        self.generation_times = []
        self.quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.float16,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",  # ã‚ˆã‚Šå®‰å®šã—ãŸé‡å­åŒ–ã‚¿ã‚¤ãƒ—
        )

        # ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆAnime-Llasa-3B-Demoã¨åŒã˜ï¼‰
        self.REPLACE_MAP = {
            r"\t": "",
            r"\[n\]": "",
            r" ": "",
            r"ã€€": "",
            r"[;â–¼â™€â™‚ã€Šã€‹â‰ªâ‰«î˜¾â‘ â‘¡â‘¢â‘£â‘¤â‘¥]": "",
            r"[\u02d7\u2010-\u2015\u2043\u2212\u23af\u23e4\u2500\u2501\u2e3a\u2e3b]": "",
            r"[\uff5e\u301C]": "ãƒ¼",
            r"ï¼Ÿ": "?",
            r"ï¼": "!",
            r"[â—â—¯ã€‡]": "â—‹",
            r"â™¥": "â™¡",
        }

        # æ–‡å­—ç¨®å¤‰æ›ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.FULLWIDTH_ALPHA_TO_HALFWIDTH = str.maketrans(
            {
                chr(full): chr(half)
                for full, half in zip(
                    list(range(0xFF21, 0xFF3B)) + list(range(0xFF41, 0xFF5B)),
                    list(range(0x41, 0x5B)) + list(range(0x61, 0x7B)),
                )
            }
        )

        self.HALFWIDTH_KATAKANA_TO_FULLWIDTH = str.maketrans(
            {chr(half): chr(full) for half, full in zip(range(0xFF61, 0xFF9F), range(0x30A1, 0x30FB))}
        )

        self.FULLWIDTH_DIGITS_TO_HALFWIDTH = str.maketrans(
            {chr(full): chr(half) for full, half in zip(range(0xFF10, 0xFF1A), range(0x30, 0x3A))}
        )

        # ç„¡åŠ¹æ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆAnime-Llasa-3B-Demoã¨åŒã˜ï¼‰
        self.INVALID_PATTERN = re.compile(
            r"[^\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\u3400-\u4DBF\u3005"
            r"\u0041-\u005A\u0061-\u007A"
            r"\u0030-\u0039"
            r"ã€‚ã€!?â€¦â™ªâ™¡â—‹]"
        )

    def parse_arguments(self):
        """
        å¼•æ•°ã‚’è§£æã™ã‚‹ã€‚
        -m --model ã§ "NandemoGHS/Anime-Llasa-3B" ã¨ã„ã£ãŸãƒ¢ãƒ‡ãƒ«åã‚’å¼•æ•°ã‹ã‚‰æŒ‡å®šã™ã‚‹
        -b --batch_count ãƒãƒƒãƒç”Ÿæˆå›æ•°ã‚’æŒ‡å®šã™ã‚‹ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0ã§ãƒãƒƒãƒç”Ÿæˆå›æ•°ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç¢ºèªã™ã‚‹ã€‚-1ãªã‚‰ç„¡åˆ¶é™ã«ç”Ÿæˆ
        æ®‹ã‚Šã®å¼•æ•°ã¯ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã¨ã—ã¦æ‰±ã†
        """
        parser = argparse.ArgumentParser(description="Llasa voice generation tool / LlasaéŸ³å£°ç”Ÿæˆãƒ„ãƒ¼ãƒ«")

        # === åŸºæœ¬è¨­å®š (Core Settings) ===
        # ãƒ¢ãƒ‡ãƒ«æŒ‡å®š
        parser.add_argument(
            "-m",
            "--model",
            type=str,
            default="NandemoGHS/Anime-Llasa-3B",
            help="Model name to use (e.g., NandemoGHS/Anime-Llasa-3B) / ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å (ä¾‹: NandemoGHS/Anime-Llasa-3B)",
        )

        # ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆå‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        parser.add_argument(
            "paths",
            nargs="*",
            help="List of sound file paths to process (text is loaded from specified text file) / å‡¦ç†ã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¯æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰",
        )

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
        parser.add_argument(
            "-t",
            "--text",
            type=str,
            default="Dialogue.txt",
            help="Text file path to load dialogue lines from (default: Dialogue.txt) / å°è©ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Dialogue.txtï¼‰",
        )

        # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
        parser.add_argument(
            "-o",
            "--output",
            type=str,
            default="Output",
            help="Output directory for generated audio files (default: Output) / ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Outputï¼‰",
        )

        # === å‹•ä½œãƒ¢ãƒ¼ãƒ‰ (Operation Mode) ===
        # ç¶™ç¶šãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ï¼‰- åå‰ä»˜ããƒ‘ã‚¤ãƒ—ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡
        parser.add_argument(
            "--server",
            action="store_true",
            default=False,
            help="Run in server mode using named pipe for inter-process communication / åå‰ä»˜ããƒ‘ã‚¤ãƒ—ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ã§ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ",
        )

        # ãƒãƒƒãƒç”Ÿæˆå›æ•°æŒ‡å®š
        parser.add_argument(
            "-b",
            "--batch_count",
            type=int,
            default=0,
            help="Batch generation count (0: prompt for confirmation, -1: unlimited generation, other: specified number) / ãƒãƒƒãƒç”Ÿæˆå›æ•° (0: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç¢ºèª, -1: ç„¡åˆ¶é™ç”Ÿæˆ, ãã®ä»–: æŒ‡å®šæ•°)",
        )

        # === ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»æœ€é©åŒ– (Performance Optimization) ===
        # é‡å­åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        parser.add_argument(
            "-q",
            "--quantization",
            action="store_true",
            default=False,
            help="Enable 4bit quantization for VRAM efficiency (may slightly reduce quality) / VRAMåŠ¹ç‡åŒ–ã®ãŸã‚4bité‡å­åŒ–ã‚’æœ‰åŠ¹åŒ–ï¼ˆå“è³ªãŒã‚ãšã‹ã«ä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ï¼‰",
        )

        # === ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Generation Parameters) ===
        parser.add_argument(
            "--temperature",
            type=float,
            default=0.8,
            help="Temperature for text generation (default: 0.8) / ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.8ï¼‰",
        )

        parser.add_argument(
            "--top_p",
            type=float,
            default=1.0,
            help="Top-p value for nucleus sampling (default: 1.0) / ãƒ‹ãƒ¥ãƒ¼ãƒªã‚¢ã‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®top-på€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰",
        )

        parser.add_argument(
            "--repetition_penalty",
            type=float,
            default=1.1,
            help="Repetition penalty for text generation (default: 1.1) / ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ç¹°ã‚Šè¿”ã—ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.1ï¼‰",
        )

        # === å‡ºåŠ›ãƒ»å†ç”Ÿ (Output & Playback) ===
        # éŸ³å£°å†ç”Ÿã‚ªãƒ—ã‚·ãƒ§ãƒ³
        parser.add_argument(
            "-p",
            "--play",
            action="store_true",
            default=False,
            help="Play generated audio using ffplay.exe (skips if previous playback is still running) / ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ã‚’ffplay.exeã§å†ç”Ÿï¼ˆå‰å›ã®å†ç”ŸãŒå®Ÿè¡Œä¸­ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰",
        )

        # éŸ³é‡è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
        parser.add_argument(
            "-v",
            "--volume",
            type=float,
            default=1.0,
            help="Volume level for audio playbook (0.0-2.0, default: 1.0) / éŸ³å£°å†ç”Ÿã®éŸ³é‡ãƒ¬ãƒ™ãƒ«ï¼ˆ0.0-2.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰",
        )

        # å†ç”Ÿé€Ÿåº¦è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
        parser.add_argument(
            "-s",
            "--speed",
            type=float,
            default=1.0,
            help="Playback speed for audio playbook (0.5-2.0, default: 1.0) / éŸ³å£°å†ç”Ÿã®å†ç”Ÿé€Ÿåº¦ï¼ˆ0.5-2.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰",
        )

        # === ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚° (Testing & Debug) ===
        # ãƒ†ã‚¹ãƒˆç”¨ã‚·ãƒ¼ãƒ‰è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
        parser.add_argument(
            "--test-seed",
            type=int,
            default=None,
            help="Random seed for reproducible test results (for testing purposes only, default: None - random seed) / ãƒ†ã‚¹ãƒˆç”¨ã®å†ç¾å¯èƒ½ãªçµæœã®ãŸã‚ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆãƒ†ã‚¹ãƒˆç›®çš„ã®ã¿ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: None - ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼‰",
        )

        args = parser.parse_args()

        # ã‚¯ãƒ©ã‚¹å±æ€§ã«è¨­å®š
        self.model = args.model
        self.batch_count = args.batch_count
        # é‡å­åŒ–è¨­å®š: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Falseã€--quantizationãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°True
        self.quantization_enabled = args.quantization
        # éŸ³å£°å†ç”Ÿè¨­å®š
        self.play_audio = args.play
        # éŸ³é‡è¨­å®šï¼ˆ0.0-2.0ã®ç¯„å›²ã§ãƒã‚§ãƒƒã‚¯ï¼‰
        self.volume = max(0.0, min(2.0, args.volume))
        if args.volume != self.volume:
            print(
                f"Warning: Volume clamped to valid range: {args.volume} -> {self.volume} / è­¦å‘Š: éŸ³é‡ã‚’æœ‰åŠ¹ç¯„å›²ã«èª¿æ•´: {args.volume} -> {self.volume}"
            )
        # å†ç”Ÿé€Ÿåº¦è¨­å®šï¼ˆ0.5-2.0ã®ç¯„å›²ã§ãƒã‚§ãƒƒã‚¯ï¼‰
        self.speed = max(0.5, min(2.0, args.speed))
        if args.speed != self.speed:
            print(
                f"Warning: Speed clamped to valid range: {args.speed} -> {self.speed} / è­¦å‘Š: å†ç”Ÿé€Ÿåº¦ã‚’æœ‰åŠ¹ç¯„å›²ã«èª¿æ•´: {args.speed} -> {self.speed}"
            )
        # ãƒ‡ãƒ¼ãƒ¢ãƒ³ãƒ¢ãƒ¼ãƒ‰è¨­å®šï¼ˆåå‰ä»˜ããƒ‘ã‚¤ãƒ—ä½¿ç”¨ï¼‰
        self.server_mode = args.server
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
        self.text_file_path = args.text
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.output_dir = args.output
        # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        self.temperature = args.temperature
        self.top_p = args.top_p
        self.repetition_penalty = args.repetition_penalty
        # ãƒ†ã‚¹ãƒˆç”¨ã‚·ãƒ¼ãƒ‰è¨­å®š
        self.seed = args.test_seed
        self.paths = args.paths

        # ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã«å‡¦ç†ï¼‰
        if self.server_mode:
            self.sound_files = []
            return args

        # ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‹ã‚‰sound_filesã‚’ç”¨æ„ã™ã‚‹ã€‚
        # ãƒ•ã‚©ãƒ«ãƒ€ãªã‚‰å†å¸°çš„ã«æ¢ç´¢ã™ã‚‹ã€‚
        # sound_files ã¯ import soundfile ãŒèª­ã¿è¾¼ã¿å¯èƒ½ãªæ‹¡å¼µå­ã€‚

        self.sound_files = []

        # soundfileãŒå¯¾å¿œã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
        audio_extensions = {".wav", ".flac", ".ogg", ".mp3", ".aiff", ".au", ".caf"}

        for path in self.paths:
            # ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›ã€ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’çµ±ä¸€ï¼‰
            normalized_path = os.path.abspath(os.path.normpath(path))

            # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(normalized_path):
                # å…ƒã®ãƒ‘ã‚¹ã§ã‚‚è©¦ã—ã¦ã¿ã‚‹
                if os.path.exists(path):
                    normalized_path = path
                else:
                    print(
                        f"Warning: Path does not exist: {normalized_path} / è­¦å‘Š: ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {normalized_path}"
                    )
                    continue

            # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ã‚’ä½¿ç”¨
            path = normalized_path

            if os.path.isdir(path):
                # ãƒ•ã‚©ãƒ«ãƒ€ãªã‚‰å†å¸°çš„ã«æ¢ç´¢
                for root, dirs, files in os.walk(path):
                    for filename in files:
                        file_path = os.path.join(root, filename)
                        file_ext = os.path.splitext(filename)[1].lower()

                        if file_ext in audio_extensions:
                            self.sound_files.append(file_path)
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãªã‚‰æ‹¡å¼µå­ã§åˆ¤åˆ¥
                file_ext = os.path.splitext(path)[1].lower()

                if file_ext in audio_extensions:
                    self.sound_files.append(path)

        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢çµæœã‚’è¡¨ç¤º
        print(f"Found {len(self.sound_files)} sound files. / éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«{len(self.sound_files)}å€‹ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚")

        # sound_files ãŒç©ºãªã‚‰ã‚¨ãƒ©ãƒ¼ã§çµ‚äº†ï¼ˆãƒ‡ãƒ¼ãƒ¢ãƒ³ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯é™¤ãï¼‰
        if not self.sound_files and not self.server_mode:
            raise ValueError(
                "Error: No valid sound files found. Please provide sound files in supported formats (.wav, .flac, .ogg, .mp3, .aiff, .au, .caf). / "
                "ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¯¾å¿œå½¢å¼ï¼ˆ.wav, .flac, .ogg, .mp3, .aiff, .au, .cafï¼‰ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
            )

        return args

    def _collect_audio_data(self):
        """ã‚µã‚¦ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã—ã€æœ‰åŠ¹ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹ï¼ˆWhisperè»¢å†™ãƒ™ãƒ¼ã‚¹ï¼‰"""
        for sound_file in self.sound_files:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå®Ÿéš›ã«èª­ã¿è¾¼ã¿å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            try:
                # soundfileã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                waveform, sample_rate = sf.read(sound_file)

                if len(waveform) == 0:
                    print(f"Warning: Empty audio file: {sound_file} / è­¦å‘Š: ç©ºã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {sound_file}")
                    continue

                # éŸ³å£°é•·ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ15ç§’åˆ¶é™ï¼‰
                duration = len(waveform) / sample_rate
                if duration > 15.0:
                    print(
                        f"Warning: Audio too long ({duration:.2f}s), trimming to 15s: {sound_file} / è­¦å‘Š: éŸ³å£°ãŒé•·ã™ãã¾ã™ï¼ˆ{duration:.2f}ç§’ï¼‰ã€15ç§’ã«åˆ‡ã‚Šè©°ã‚ã¾ã™: {sound_file}"
                    )
                    waveform = waveform[: int(sample_rate * 15)]
                    duration = 15.0

                # ã‚¹ãƒ†ãƒ¬ã‚ªã‚’ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
                if len(waveform.shape) > 1 and waveform.shape[1] > 1:
                    waveform = np.mean(waveform, axis=1)
                    print(
                        f"Info: Converted stereo to mono: {sound_file} / æƒ…å ±: ã‚¹ãƒ†ãƒ¬ã‚ªã‚’ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›: {sound_file}"
                    )

                # 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå¿…è¦ãªå ´åˆï¼‰
                target_rate = 16000
                if sample_rate != target_rate:
                    # ç°¡æ˜“ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã«ã¯torchã®resampleã‚’ä½¿ç”¨ã™ã‚‹ï¼‰
                    print(
                        f"Info: Audio needs resampling from {sample_rate}Hz to {target_rate}Hz: {sound_file} / æƒ…å ±: {sample_rate}Hzã‹ã‚‰{target_rate}Hzã¸ã®ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå¿…è¦: {sound_file}"
                    )

                self.audio_data.append(
                    {
                        "file": sound_file,
                        "duration": duration,
                        "samplerate": sample_rate,
                        "channels": 1 if len(waveform.shape) == 1 else waveform.shape[1],
                        "needs_resampling": sample_rate != target_rate,
                        "waveform_shape": waveform.shape,
                    }
                )

            except Exception as e:
                print(
                    f"Warning: Could not read audio file {sound_file}: {e} / è­¦å‘Š: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ {sound_file}: {e}"
                )
                continue

        print(
            f"Collected {len(self.audio_data)} valid audio files. / {len(self.audio_data)}å€‹ã®æœ‰åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã—ã¾ã—ãŸã€‚"
        )

        if not self.audio_data and not self.server_mode:
            raise ValueError(
                "Error: No valid audio files found. Please ensure audio files are in supported formats and accessible. / "
                "ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å½¢å¼ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )

    def _collect_audio_files_from_path(self, input_path):
        """å…¥åŠ›ãƒ‘ã‚¹ã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã™ã‚‹"""
        audio_extensions = {".wav", ".flac", ".ogg", ".mp3", ".aiff", ".au", ".caf"}
        audio_files = []

        if os.path.isfile(input_path):
            # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
            if any(input_path.lower().endswith(ext) for ext in audio_extensions):
                audio_files.append(input_path)
        elif os.path.isdir(input_path):
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆã€å†å¸°çš„ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            for root, dirs, files in os.walk(input_path):
                for file in files:
                    if any(file.lower().endswith(ext) for ext in audio_extensions):
                        audio_files.append(os.path.join(root, file))

        return sorted(audio_files)

    def _load_dialogue_txt(self):
        """æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªè¡Œã‚’åé›†ã™ã‚‹ï¼ˆãƒªãƒ¼ãƒ‰ã‚ªãƒ³ãƒªãƒ¼ã§å†èª­ã¿è¾¼ã¿ï¼‰"""
        dialogue_file = self.text_file_path

        # æ—¢å­˜ã®text_linesã‚’ã‚¯ãƒªã‚¢
        self.text_lines = []

        print(f"Loading text lines from {dialogue_file}... / {dialogue_file}ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’èª­ã¿è¾¼ã¿ä¸­...")

        if not os.path.exists(dialogue_file):
            raise ValueError(
                f"Error: {dialogue_file} not found. Please create the text file with text lines to generate. / "
                f"ã‚¨ãƒ©ãƒ¼: {dialogue_file}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            )

        try:
            with open(dialogue_file, "r", encoding="utf-8-sig") as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()

                    # ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if not line:
                        continue

                    # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ#ã§å§‹ã¾ã‚‹è¡Œï¼‰
                    if line.startswith("#"):
                        continue

                    # èª­ã¿ä¸Šã’ä¸å¯èƒ½ãªæ–‡å­—ã®ãƒã‚§ãƒƒã‚¯ï¼ˆåˆ¶å¾¡æ–‡å­—ãªã©ï¼‰
                    if self._is_readable_line(line):
                        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
                        normalized_text = self.normalize_text(line)

                        # æ­£è¦åŒ–å¾Œã‚‚æœ‰åŠ¹ãªæ–‡å­—ãŒæ®‹ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        if normalized_text and self._is_readable_line(normalized_text):
                            # ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™ï¼ˆ300æ–‡å­—ï¼‰
                            if len(normalized_text) > 300:
                                print(
                                    f"Warning: Text too long ({len(normalized_text)} chars), truncating to 300 chars: {dialogue_file}:{line_num} / è­¦å‘Š: ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆ{len(normalized_text)}æ–‡å­—ï¼‰ã€300æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚ã¾ã™: {dialogue_file}:{line_num}"
                                )
                                normalized_text = normalized_text[:300]

                            self.text_lines.append(
                                {
                                    "text": normalized_text,
                                    "original_text": line,
                                    "file": dialogue_file,
                                    "line_number": line_num,
                                }
                            )

        except UnicodeDecodeError:
            print(
                f"Warning: Failed to decode file {dialogue_file}, trying with different encoding / è­¦å‘Š: ãƒ•ã‚¡ã‚¤ãƒ«{dialogue_file}ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã€åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ"
            )
            try:
                with open(dialogue_file, "r", encoding="shift_jis") as f:
                    for line_num, line in enumerate(f, 1):
                        line = line.strip()
                        if line and not line.startswith("#") and self._is_readable_line(line):
                            # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
                            normalized_text = self.normalize_text(line)

                            # æ­£è¦åŒ–å¾Œã‚‚æœ‰åŠ¹ãªæ–‡å­—ãŒæ®‹ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                            if normalized_text and self._is_readable_line(normalized_text):
                                # ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™ï¼ˆ300æ–‡å­—ï¼‰
                                if len(normalized_text) > 300:
                                    print(
                                        f"Warning: Text too long ({len(normalized_text)} chars), truncating to 300 chars: {dialogue_file}:{line_num} / è­¦å‘Š: ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆ{len(normalized_text)}æ–‡å­—ï¼‰ã€300æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚ã¾ã™: {dialogue_file}:{line_num}"
                                    )
                                    normalized_text = normalized_text[:300]

                                self.text_lines.append(
                                    {
                                        "text": normalized_text,
                                        "original_text": line,
                                        "file": dialogue_file,
                                        "line_number": line_num,
                                    }
                                )
            except Exception as e:
                print(
                    f"Error: Could not read file {dialogue_file}: {e} / ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«{dialogue_file}ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“: {e}"
                )
                raise

        except Exception as e:
            print(
                f"Error: Could not read file {dialogue_file}: {e} / ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«{dialogue_file}ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“: {e}"
            )
            raise

        print(
            f"Collected {len(self.text_lines)} valid text lines from {dialogue_file}. / {dialogue_file}ã‹ã‚‰{len(self.text_lines)}è¡Œã®æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†ã—ã¾ã—ãŸã€‚"
        )

        if not self.text_lines:
            raise ValueError(
                f"Error: No valid text lines found in {dialogue_file}. / "
                f"ã‚¨ãƒ©ãƒ¼: {dialogue_file}ã«æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆè¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            )

    def _display_generation_summary(self):
        """è£œæ­£æ¸ˆã¿ã®ã‚µã‚¦ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã®èª­ã¿ä¸€è¦§ã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ç·ç”Ÿæˆæ•°ã‚’è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("LLASA VOICE GENERATION SUMMARY / LlasaéŸ³å£°ç”Ÿæˆã‚µãƒãƒªãƒ¼")
        print("=" * 80)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        print(f"\nAUDIO FILES ({len(self.audio_data)} items) / éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ({len(self.audio_data)}å€‹):")
        print("-" * 60)
        for i, audio_data in enumerate(self.audio_data, 1):
            filename = os.path.basename(audio_data["file"])
            print(f"  {i:2d}. {filename} ({audio_data['duration']:.1f}s)")

        # ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸€è¦§
        print(f"\nTEXT READINGS ({len(self.text_lines)} items) / ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸€è¦§ ({len(self.text_lines)}å€‹):")
        print("-" * 60)
        for i, text_data in enumerate(self.text_lines, 1):
            # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¯çœç•¥è¡¨ç¤º
            display_text = text_data["text"]
            if len(display_text) > 50:
                display_text = display_text[:47] + "..."
            print(f"  {i:2d}. {display_text}")

        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã®è¨ˆç®—
        batch_size = len(self.audio_data) * len(self.text_lines)

        print("\n" + "=" * 80)
        print("BATCH SIZE AND GENERATION COUNT / ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ç”Ÿæˆæ•°")
        print("=" * 80)
        print(f"Batch size: {len(self.audio_data)} audio Ã— {len(self.text_lines)} text = {batch_size} combinations")
        print(
            f"ãƒãƒƒãƒã‚µã‚¤ã‚º: éŸ³å£°{len(self.audio_data)}å€‹ Ã— ãƒ†ã‚­ã‚¹ãƒˆ{len(self.text_lines)}è¡Œ = {batch_size}å€‹ã®çµ„ã¿åˆã‚ã›"
        )

        # ãƒãƒƒãƒã‚«ã‚¦ãƒ³ãƒˆã«å¿œã˜ãŸç·ç”Ÿæˆæ•°ã®è¡¨ç¤º
        if self.batch_count == -1:
            print("\nGeneration mode: PERPETUAL / ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰: æ°¸ç¶šç”Ÿæˆ")
            print("The system will generate continuously until stopped.")
            print("ã‚·ã‚¹ãƒ†ãƒ ã¯åœæ­¢ã•ã‚Œã‚‹ã¾ã§ç¶™ç¶šçš„ã«ç”Ÿæˆã—ã¾ã™ã€‚")
        elif self.batch_count == 0:
            # ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚å¯¾è©±çš„å…¥åŠ›ã‚’å¯èƒ½ã«ã™ã‚‹
            print("\nGeneration mode: INTERACTIVE / ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰: å¯¾è©±çš„")
            if self.server_mode:
                print("Server mode with interactive batch count / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã®å¯¾è©±çš„ãƒãƒƒãƒæ•°è¨­å®š")
            try:
                user_input = input("Enter the number of batches to generate / ç”Ÿæˆã™ã‚‹ãƒãƒƒãƒæ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
                user_batches = int(user_input.strip())
                if user_batches <= 0 and user_batches != -1:
                    raise ValueError("Batch count must be greater than 0 / ãƒãƒƒãƒæ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                # å¯¾è©±ã§å…¥åŠ›ã•ã‚ŒãŸãƒãƒƒãƒæ•°ã‚’ä¿å­˜
                self.batch_count = user_batches
                if user_batches == -1:
                    print("Perpetual generation mode selected / æ°¸ç¶šç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
                    print("The system will generate continuously until stopped (Ctrl+C)")
                    print("ã‚·ã‚¹ãƒ†ãƒ ã¯åœæ­¢ã•ã‚Œã‚‹ã¾ã§ç¶™ç¶šçš„ã«ç”Ÿæˆã—ã¾ã™ (Ctrl+C)")
                else:
                    total_generations = batch_size * user_batches
                    print(f"Total generations: {batch_size} Ã— {user_batches} = {total_generations}")
                    print(f"ç·ç”Ÿæˆæ•°: {batch_size} Ã— {user_batches} = {total_generations}")
            except ValueError as e:
                if "invalid literal" in str(e):
                    raise ValueError(
                        "Invalid input. Please enter a valid number / ç„¡åŠ¹ãªå…¥åŠ›ã§ã™ã€‚æœ‰åŠ¹ãªæ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
                    )
                else:
                    raise e
        else:
            print(
                f"\nGeneration mode: SPECIFIED ({self.batch_count} batches) / ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰: æŒ‡å®š ({self.batch_count}ãƒãƒƒãƒ)"
            )
            total_generations = batch_size * self.batch_count
            print(f"Total generations: {batch_size} Ã— {self.batch_count} = {total_generations}")
            print(f"ç·ç”Ÿæˆæ•°: {batch_size} Ã— {self.batch_count} = {total_generations}")

        print("=" * 80)

    def _is_readable_line(self, line):
        """è¡ŒãŒèª­ã¿ä¸Šã’å¯èƒ½ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹"""
        # åˆ¶å¾¡æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¿ãƒ–ã¯é™¤ãï¼‰
        if any(ord(char) < 32 and char not in ["\t"] for char in line):
            return False

        # æœ€å°æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆ1æ–‡å­—ä»¥ä¸Šï¼‰
        if len(line.strip()) < 1:
            return False

        # Anime-Llasa-3B-Demoã¨åŒã˜èª­ã¿ä¸Šã’å¯èƒ½æ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨
        # ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã€è‹±å­—ã€æ•°å­—ã€åŸºæœ¬çš„ãªå¥èª­ç‚¹ã‚’è¨±å¯
        valid_pattern = re.compile(
            r"[\u3040-\u309F"  # ã²ã‚‰ãŒãª
            r"\u30A0-\u30FF"  # ã‚«ã‚¿ã‚«ãƒŠ
            r"\u4E00-\u9FFF"  # CJKçµ±åˆæ¼¢å­—
            r"\u3400-\u4DBF"  # CJKæ‹¡å¼µA
            r"\u3005"  # ã€…
            r"\u0041-\u005A"  # å¤§æ–‡å­—è‹±å­—
            r"\u0061-\u007A"  # å°æ–‡å­—è‹±å­—
            r"\u0030-\u0039"  # æ•°å­—
            r"ã€‚ã€!?â€¦â™ªâ™¡â—‹"  # åŸºæœ¬çš„ãªå¥èª­ç‚¹ãƒ»è¨˜å·
            r"\s]"  # ç©ºç™½æ–‡å­—
        )

        # æœ‰åŠ¹ãªæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        valid_chars = len(valid_pattern.findall(line))
        total_chars = len(line.strip())

        # å°‘ãªãã¨ã‚‚50%ä»¥ä¸ŠãŒæœ‰åŠ¹ãªæ–‡å­—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹
        return valid_chars > 0 and (valid_chars / total_chars) >= 0.5

    def normalize_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°åˆæˆç”¨ã«æ­£è¦åŒ–ã™ã‚‹ï¼ˆAnime-Llasa-3B-Demoã¨åŒã˜å‡¦ç†ï¼‰"""
        # REPLACE_MAPã«ã‚ˆã‚‹ç½®ãæ›ãˆ
        for pattern, replacement in self.REPLACE_MAP.items():
            text = re.sub(pattern, replacement, text)

        # æ–‡å­—ç¨®å¤‰æ›
        text = text.translate(self.FULLWIDTH_ALPHA_TO_HALFWIDTH)
        text = text.translate(self.FULLWIDTH_DIGITS_TO_HALFWIDTH)
        text = text.translate(self.HALFWIDTH_KATAKANA_TO_FULLWIDTH)

        # é€£ç¶šã™ã‚‹ä¸‰ç‚¹ãƒªãƒ¼ãƒ€ãƒ¼ã‚’äºŒç‚¹ãƒªãƒ¼ãƒ€ãƒ¼ã«æ­£è¦åŒ–
        text = re.sub(r"â€¦{3,}", "â€¦â€¦", text)

        # ç„¡åŠ¹æ–‡å­—ã‚’é™¤å»
        text = self.INVALID_PATTERN.sub("", text)
        text = text.strip()

        # æœ«å°¾ã®ã€Œã€‚ã€ã‚’å‰Šé™¤
        if text.endswith("ã€‚"):
            text = text[:-1]

        return text.strip()

    def _play_audio(self, audio_path, is_last=False):
        """
        ffplay.exeã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’å†ç”Ÿã™ã‚‹
        å‰å›ã®å†ç”ŸãŒã¾ã å®Ÿè¡Œä¸­ã®å ´åˆã¯å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ï¼ˆæœ€å¾Œã®éŸ³å£°ä»¥å¤–ï¼‰
        is_last=Trueã®å ´åˆã¯å†ç”Ÿå®Œäº†ã¾ã§å¾…æ©Ÿã™ã‚‹
        """
        if not self.play_audio:
            return

        # å‰å›ã®å†ç”Ÿãƒ—ãƒ­ã‚»ã‚¹ãŒã¾ã å®Ÿè¡Œä¸­ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å¾Œã®éŸ³å£°ä»¥å¤–ï¼‰
        if not is_last and self.ffplay_process is not None:
            if self.ffplay_process.poll() is None:  # ãƒ—ãƒ­ã‚»ã‚¹ãŒã¾ã å®Ÿè¡Œä¸­
                print(
                    "â­ï¸  Skipping playback (previous playback is still running) / å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå‰å›ã®å†ç”ŸãŒã¾ã å®Ÿè¡Œä¸­ï¼‰"
                )
                return

        try:
            # venv\Scriptså†…ã®ffplay.exeã®å®Œå…¨ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            script_dir = os.path.dirname(os.path.abspath(__file__))  # EasyLlasaãƒ•ã‚©ãƒ«ãƒ€
            project_root = os.path.dirname(script_dir)  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
            ffplay_path = os.path.join(project_root, "venv", "Scripts", "ffplay.exe")

            # ffplay.exeãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not os.path.exists(ffplay_path):
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§PATHã‹ã‚‰ffplay.exeã‚’æ¢ã™
                ffplay_path = "ffplay.exe"

            # ffplay.exeã§éŸ³å£°ã‚’å†ç”Ÿï¼ˆä¸€å›å†ç”Ÿå¾Œè‡ªå‹•çµ‚äº†ã€éŸ³é‡è¨­å®šãƒ»å†ç”Ÿé€Ÿåº¦ä»˜ãï¼‰
            command = [ffplay_path, "-nodisp", "-autoexit", "-volume", str(int(self.volume * 100))]
            # å†ç”Ÿé€Ÿåº¦ãŒ1.0ã§ãªã„å ´åˆã€atempoãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¿½åŠ 
            if self.speed != 1.0:
                command.extend(["-af", f"atempo={self.speed}"])
            command.append(audio_path)
            self.ffplay_process = subprocess.Popen(
                command,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )

            if is_last:
                print(
                    f"ğŸ”Š Playing final audio (vol: {self.volume:.1f}): {os.path.basename(audio_path)} / æœ€çµ‚éŸ³å£°ã‚’å†ç”Ÿä¸­ (éŸ³é‡: {self.volume:.1f}): {os.path.basename(audio_path)}"
                )
                print("â³ Waiting for final audio playback to complete... / æœ€çµ‚éŸ³å£°ã®å†ç”Ÿå®Œäº†ã‚’å¾…æ©Ÿä¸­...")
                # æœ€å¾Œã®éŸ³å£°ã®å ´åˆã¯å†ç”Ÿå®Œäº†ã¾ã§å¾…æ©Ÿ
                self.ffplay_process.wait()
                print("âœ… Final audio playback completed / æœ€çµ‚éŸ³å£°ã®å†ç”ŸãŒå®Œäº†ã—ã¾ã—ãŸ")
            else:
                print(
                    f"ğŸ”Š Playing audio (vol: {self.volume:.1f}): {os.path.basename(audio_path)} / éŸ³å£°ã‚’å†ç”Ÿä¸­ (éŸ³é‡: {self.volume:.1f}): {os.path.basename(audio_path)}"
                )
        except FileNotFoundError:
            print("âš ï¸  ffplay.exe not found in PATH / ffplay.exeãŒPATHã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            print(f"âš ï¸  Failed to play audio: {e} / éŸ³å£°å†ç”Ÿã«å¤±æ•—: {e}")

    def _format_time(self, seconds):
        """ç§’ã‚’æ™‚:åˆ†:ç§’ã®å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        if hours > 0:
            return f"{hours}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes}:{secs:02d}"

    def _calculate_eta(self, completed_count, total_count, elapsed_time):
        """äºˆæƒ³æ®‹ã‚Šæ™‚é–“ã‚’è¨ˆç®—ã™ã‚‹"""
        if completed_count == 0:
            return "ä¸æ˜"

        avg_time_per_generation = elapsed_time / completed_count
        remaining_generations = total_count - completed_count
        eta_seconds = avg_time_per_generation * remaining_generations

        return self._format_time(eta_seconds)

    def _process_single_generation(self, audio_data, text_data, generated_count, total_generations):
        """å˜ä¸€ã®éŸ³å£°ç”Ÿæˆå‡¦ç†ã‚’è¡Œã†"""
        try:
            # å€‹åˆ¥ç”Ÿæˆã®é–‹å§‹æ™‚é–“
            single_generation_start = time.time()

            result = self._generate_speech(
                sample_audio_path=audio_data["file"],
                target_text=text_data["text"],
                temperature=self.temperature,
                top_p=self.top_p,
                repetition_penalty=self.repetition_penalty,
            )

            if result is not None:
                sample_rate, audio_array = result

                # ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨
                now = datetime.now()
                timestamp = f"{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}-{now.second:02d}{now.microsecond//10000:02d}"

                # ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚’èª¿æ•´ï¼ˆOSã®åˆ¶é™255æ–‡å­—ã‚’è€ƒæ…®ã€32æ–‡å­—ã®ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼‰
                # timestamp(13æ–‡å­—) + "-" + ".wav"(4æ–‡å­—) = 18æ–‡å­— + ä½™è£•32æ–‡å­— = 50æ–‡å­—ã‚’é™¤ã„ãŸ205æ–‡å­—ãŒä½¿ç”¨å¯èƒ½
                available_length = 205
                text_part = text_data["text"].replace(" ", "_")

                # ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¤§é•·ã‚’è¨­å®š
                text_max = min(len(text_part), available_length)
                text_truncated = text_part[:text_max]

                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
                output_filename = f"{timestamp}-{text_truncated}.wav"
                # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç„¡åŠ¹æ–‡å­—ã‚’é™¤å»
                output_filename = re.sub(r'[<>:"/\\|?*]', "_", output_filename)
                output_path = os.path.join(self.output_dir, output_filename)

                # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                os.makedirs(self.output_dir, exist_ok=True)

                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                sf.write(output_path, audio_array, sample_rate)
                print(f"Saved: {output_path} / ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")

                # æ™‚é–“æƒ…å ±ã‚’è¨ˆç®—ãƒ»è¡¨ç¤ºï¼ˆå†ç”Ÿå‰ã«è¨ˆæ¸¬ï¼‰
                single_generation_time = time.time() - single_generation_start
                total_elapsed_time = time.time() - self.generation_start_time
                self.generation_times.append(single_generation_time)

                # æœ€å¾Œã®éŸ³å£°ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                is_last_audio = False
                if self.batch_count != -1 and total_generations != float("inf"):
                    # æœ‰é™å›æ•°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼šæ¬¡ã®ç”Ÿæˆã§çµ‚äº†ã‹ã©ã†ã‹
                    is_last_audio = (generated_count + 1) >= total_generations

                # éŸ³å£°å†ç”Ÿï¼ˆ--playã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
                self._play_audio(output_path, is_last=is_last_audio)

                print(f"â±ï¸  Generation time: {single_generation_time:.2f}s / ç”Ÿæˆæ™‚é–“: {single_generation_time:.2f}ç§’")
                print(
                    f"ğŸ“Š Total elapsed: {self._format_time(total_elapsed_time)} / ç·çµŒéæ™‚é–“: {self._format_time(total_elapsed_time)}"
                )

                if self.batch_count != -1 and total_generations != float("inf"):
                    eta = self._calculate_eta(generated_count + 1, total_generations, total_elapsed_time)
                    print(f"â³ ETA: {eta} / äºˆæƒ³æ®‹ã‚Šæ™‚é–“: {eta}")

                return True  # æˆåŠŸ
            else:
                print("Failed to generate audio / éŸ³å£°ç”Ÿæˆå¤±æ•—")
                return False  # å¤±æ•—

        except Exception as e:
            print(f"Error generating audio: {e} / éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False  # å¤±æ•—

    def _execute_server_generation(self, audio_data, text_data, generated_count):
        """ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã®å˜ä¸€éŸ³å£°ç”Ÿæˆå‡¦ç†"""
        generation_start = time.time()

        result = self._generate_speech(
            sample_audio_path=audio_data["file"],
            target_text=text_data["text"],
            temperature=self.temperature,
            top_p=self.top_p,
            repetition_penalty=self.repetition_penalty,
        )

        if result is not None:
            sample_rate, audio_array = result

            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            now = datetime.now()
            timestamp = f"{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}-{now.second:02d}{now.microsecond//10000:02d}"
            text_part = text_data["text"].replace(" ", "_")
            text_max = min(len(text_part), 205)
            text_truncated = text_part[:text_max]
            output_filename = f"{timestamp}-{text_truncated}.wav"
            output_filename = re.sub(r'[<>:"/\\|?*]', "_", output_filename)
            output_path = os.path.join(self.output_dir, output_filename)

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            os.makedirs(self.output_dir, exist_ok=True)

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            sf.write(output_path, audio_array, sample_rate)

            generation_time = time.time() - generation_start

            print(f"      âœ… Saved: {output_path}")
            print(f"      â±ï¸  Generation time: {generation_time:.2f}s / ç”Ÿæˆæ™‚é–“: {generation_time:.2f}ç§’")

            # éŸ³å£°å†ç”Ÿï¼ˆ--playã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
            self._play_audio(output_path, is_last=False)

            return True  # æˆåŠŸ
        else:
            print("      âŒ Failed to generate audio / éŸ³å£°ç”Ÿæˆå¤±æ•—")
            return False  # å¤±æ•—

    def _setup_sage_attention(self):
        """SageAttentionã®è‡ªå‹•æ¤œå‡ºã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # å¸¸ã«è‡ªå‹•æ¤œå‡ºã‚’è©¦ã¿ã‚‹
        try:
            import sageattention

            print(
                "SageAttention auto-detected and enabled for attention optimization / SageAttentionã‚’è‡ªå‹•æ¤œå‡ºã—ã€æ³¨æ„æ©Ÿæ§‹ã®æœ€é©åŒ–ã‚’æœ‰åŠ¹åŒ–"
            )

            # SageAttentionã®æœ€é©åŒ–ã‚’é©ç”¨
            torch.backends.cuda.enable_math_sdp(False)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®SDPã‚’ç„¡åŠ¹åŒ–ã—ã¦SageAttentionã‚’å„ªå…ˆ
            print("SageAttention optimization applied / SageAttentionæœ€é©åŒ–ã‚’é©ç”¨ã—ã¾ã—ãŸ")

        except ImportError:
            print("SageAttention not available. Consider installing with: pip install sageattention")
            print("SageAttentionãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’æ¤œè¨ã—ã¦ãã ã•ã„: pip install sageattention")
        except Exception as e:
            print(f"Warning: Failed to setup SageAttention: {e}")
            print(f"è­¦å‘Š: SageAttentionã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—: {e}")

    def _load_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆé‡å­åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
        # ãƒ†ã‚¹ãƒˆç”¨ã‚·ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆå†ç¾æ€§ç¢ºä¿ã®ãŸã‚ï¼‰
        if self.seed is not None:
            torch.manual_seed(self.seed)
            torch.cuda.manual_seed(self.seed)
            torch.cuda.manual_seed_all(self.seed)
            # numpyã®ã‚·ãƒ¼ãƒ‰ã‚‚è¨­å®š
            import numpy as np

            np.random.seed(self.seed)
            # transformersã®set_seedé–¢æ•°ã‚‚ä½¿ç”¨
            from transformers import set_seed

            set_seed(self.seed)
            print(f"Test random seed set to: {self.seed} / ãƒ†ã‚¹ãƒˆç”¨ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š: {self.seed}")

        if self.quantization_enabled:
            print("Loading models with 4bit quantization for VRAM efficiency...")
            print("4bité‡å­åŒ–ã§VRAMåŠ¹ç‡åŒ–ã®ãŸã‚ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        else:
            print("Loading models without quantization (higher quality, more VRAM usage)...")
            print("é‡å­åŒ–ãªã—ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­ï¼ˆé«˜å“è³ªã€VRAMä½¿ç”¨é‡ã¯å¤šã‚ï¼‰...")

        # SageAttentionã®è‡ªå‹•æ¤œå‡ºã¨è¨­å®š
        self._setup_sage_attention()

        try:
            # Llasaãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿
            print(f"Loading Llasa model: {self.model} / Llasaãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {self.model}")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model)

            # pad_tokenãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€eos_tokenã‚’ä½¿ç”¨
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token

            model_kwargs = {
                "trust_remote_code": True,
                "device_map": "cuda",
                "low_cpu_mem_usage": True,
            }

            # é‡å­åŒ–è¨­å®šã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿å‹ã‚’èª¿æ•´ï¼ˆlogitsè­¦å‘Šã®æ ¹æœ¬è§£æ±ºï¼‰
            if self.quantization_enabled:
                model_kwargs["quantization_config"] = self.quantization_config
                # é‡å­åŒ–æ™‚ã¯float16ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ã¦logitså‹ã‚’çµ±ä¸€
                model_kwargs["torch_dtype"] = torch.float16
            else:
                # é‡å­åŒ–ãªã—ã®å ´åˆã‚‚float16ã§çµ±ä¸€
                model_kwargs["torch_dtype"] = torch.float16

            self.llasa_model = AutoModelForCausalLM.from_pretrained(self.model, **model_kwargs)
            self.llasa_model.eval()

            print("Llasa model loaded successfully / Llasaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

            # XCodec2ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®float32ã‚’ç¶­æŒï¼‰
            xcodec2_model_id = "NandemoGHS/Anime-XCodec2"
            print(f"Loading XCodec2 model: {xcodec2_model_id} / XCodec2ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {xcodec2_model_id}")
            self.codec_model = XCodec2Model.from_pretrained(xcodec2_model_id)
            self.codec_model.eval().cuda()

            print("XCodec2 model loaded successfully / XCodec2ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

            # Whisperãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆfaster-whisperï¼‰
            print(
                "Loading faster-whisper model for speech recognition... / éŸ³å£°èªè­˜ç”¨faster-whisperãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."
            )
            # GPUãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            device = "cuda" if torch.cuda.is_available() else "cpu"
            compute_type = "float16" if device == "cuda" else "int8"

            # faster-whisperãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆlarge-v3ã‚’ä½¿ç”¨ï¼‰
            self.whisper_model = WhisperModel("large-v3", device=device, compute_type=compute_type)
            print("faster-whisper model loaded successfully / faster-whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

            print("All models loaded successfully! / å…¨ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†ï¼")

        except Exception as e:
            raise RuntimeError(f"Failed to load models: {e} / ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

    def _ids_to_speech_tokens(self, speech_ids):
        """éŸ³å£°IDã‚’éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³æ–‡å­—åˆ—ã«å¤‰æ›"""
        speech_tokens_str = []
        for speech_id in speech_ids:
            speech_tokens_str.append(f"<|s_{speech_id}|>")
        return speech_tokens_str

    def _extract_speech_ids(self, speech_tokens_str):
        """éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³æ–‡å­—åˆ—ã‹ã‚‰éŸ³å£°IDã‚’æŠ½å‡º"""
        speech_ids = []
        for token_str in speech_tokens_str:
            if token_str.startswith("<|s_") and token_str.endswith("|>"):
                num_str = token_str[4:-2]
                num = int(num_str)
                speech_ids.append(num)
            else:
                print(f"Unexpected token: {token_str}")
        return speech_ids

    def _generate_speech(
        self,
        sample_audio_path: Optional[str],
        target_text: str,
        temperature: float = 0.8,
        top_p: float = 1.0,
        repetition_penalty: float = 1.1,
    ) -> Optional[Tuple[int, np.ndarray]]:
        """éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆAnime-Llasa-3B-Demoã¨åŒã˜å‡¦ç†ï¼‰"""
        if not target_text or not target_text.strip():
            print("Warning: Empty target text / è­¦å‘Š: ç©ºã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆ")
            return None

        if len(target_text) > 300:
            print(
                f"Warning: Text too long ({len(target_text)} chars), truncating to 300 / è­¦å‘Š: ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆ{len(target_text)}æ–‡å­—ï¼‰ã€300æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚ã¾ã™"
            )
            target_text = target_text[:300]

        target_text = self.normalize_text(target_text)

        with torch.no_grad():
            if sample_audio_path:
                print(f"Loading reference audio: {sample_audio_path} / å‚ç…§éŸ³å£°ã‚’èª­ã¿è¾¼ã¿ä¸­: {sample_audio_path}")
                waveform, sample_rate = torchaudio.load(sample_audio_path)

                if len(waveform[0]) / sample_rate > 15:
                    print("Warning: Trimming audio to first 15secs / è­¦å‘Š: éŸ³å£°ã‚’æœ€åˆã®15ç§’ã«åˆ‡ã‚Šè©°ã‚ã¾ã™")
                    waveform = waveform[:, : sample_rate * 15]

                # ã‚¹ãƒ†ãƒ¬ã‚ªã‚’ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
                if waveform.size(0) > 1:
                    waveform_mono = torch.mean(waveform, dim=0, keepdim=True)
                else:
                    waveform_mono = waveform

                prompt_wav = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform_mono)
                prompt_wav_len = prompt_wav.shape[1]
                prompt_text = None

                # éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹æ™‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦èª­ã¿è¾¼ã‚€
                if prompt_text is None:
                    # å¯¾å¿œã™ã‚‹æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆæ‹¡å¼µå­
                    prompt_text_file_extensions = {".txt", ".prompt"}

                    # éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ï¼Ÿ
                    prompt_text_path = None
                    for e in prompt_text_file_extensions:
                        p = f"{sample_audio_path}{e}"
                        if os.path.isfile(p):
                            prompt_text_path = p

                    # éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ãªã‚‰ã€èª­ã¿è¾¼ã‚€
                    if prompt_text_path is not None:
                        prompt_text_file = None
                        try:
                            with open(prompt_text_path, "r", encoding="utf-8", newline=None) as f:
                                prompt_text_file = f.read()
                            prompt_text = "".join(prompt_text_file.splitlines()).strip()
                            print(f"Prompt text ({prompt_text_path}): {prompt_text} / æŒ‡ç¤ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ ({prompt_text_path}): {prompt_text}")
                        except Exception as e:
                            print(f"Warning: Failed to open {prompt_text_path}: {e} / è­¦å‘Š: æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ªãƒ¼ãƒ—ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ {prompt_text_path} : {e}")

                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæœªè¨­å®šãªã‚‰ã€ faster-whisperã§æ–‡å­—èµ·ã“ã—
                if prompt_text is None:
                    # éŸ³å£°ã‚’è»¢å†™ï¼ˆfaster-whisperï¼‰
                    audio_numpy = prompt_wav[0].numpy()

                    # faster-whisperã§éŸ³å£°ã‚’è»¢å†™
                    segments, info = self.whisper_model.transcribe(audio_numpy, language="ja", beam_size=5)
                    prompt_text = "".join([segment.text for segment in segments]).strip()

                    print(f"Transcribed text: {prompt_text} / è»¢å†™ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {prompt_text}")

                # è»¢å†™ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
                prompt_text = self.normalize_text(prompt_text)
                print(f"Normalized transcribed text: {prompt_text} / æ­£è¦åŒ–ã•ã‚ŒãŸè»¢å†™ãƒ†ã‚­ã‚¹ãƒˆ: {prompt_text}")

                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéŸ³å£°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆXCodec2ã«ã¯float32ã§æ¸¡ã™ï¼‰
                prompt_wav_float32 = prompt_wav.to(torch.float32)
                vq_code_prompt = self.codec_model.encode_code(input_waveform=prompt_wav_float32)[0, 0, :]
                speech_ids_prefix = self._ids_to_speech_tokens(vq_code_prompt)
                input_text = prompt_text + " " + target_text
                assistant_content = "<|SPEECH_GENERATION_START|>" + "".join(speech_ids_prefix)
            else:
                input_text = target_text
                assistant_content = "<|SPEECH_GENERATION_START|>"
                speech_ids_prefix = []
                prompt_wav_len = 0

            print("Generating speech tokens... / éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆä¸­...")
            formatted_text = f"<|TEXT_UNDERSTANDING_START|>{input_text}<|TEXT_UNDERSTANDING_END|>"

            chat = [
                {"role": "user", "content": "Convert the text to speech:" + formatted_text},
                {"role": "assistant", "content": assistant_content},
            ]

            input_ids = self.tokenizer.apply_chat_template(
                chat, tokenize=True, return_tensors="pt", continue_final_message=True
            ).to("cuda")

            # Create attention mask to avoid warnings
            attention_mask = torch.ones_like(input_ids).to("cuda")

            speech_end_id = self.tokenizer.convert_tokens_to_ids("<|SPEECH_GENERATION_END|>")

            outputs = self.llasa_model.generate(
                input_ids,
                attention_mask=attention_mask,
                max_length=2048,  # å›ºå®šå€¤
                eos_token_id=[speech_end_id, self.tokenizer.eos_token_id],
                pad_token_id=self.tokenizer.pad_token_id,
                do_sample=True,
                top_p=top_p,
                temperature=temperature,
                repetition_penalty=repetition_penalty,
                # è¿½åŠ : æœ€ä½é™ã„ãã‚‰ã‹ã®æ–°è¦ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã•ã›ã€æ¥µç«¯ã«çŸ­ã„ç”Ÿæˆã§<|SPEECH_GENERATION_END|>ã«åˆ°é”ã—ã¦ã—ã¾ã†ã®ã‚’å›é¿
                # ï¼ˆçŸ­ã™ãã‚‹ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ†ã‚’å·®ã—å¼•ã„ãŸå¾Œã«ç©ºã«ãªã‚Š 1KB å‰å¾Œã®wavã«ãªã‚‹ï¼‰
                min_new_tokens=16,
            )

            # Extract the speech tokens exactly like demo code
            if sample_audio_path:
                generated_ids = outputs[0][input_ids.shape[1] - len(speech_ids_prefix) : -1]
            else:
                generated_ids = outputs[0][input_ids.shape[1] : -1]

            speech_tokens = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)

            speech_tokens = self._extract_speech_ids(speech_tokens)

            if not speech_tokens:
                print(
                    "Error: Audio generation failed - no speech tokens generated / ã‚¨ãƒ©ãƒ¼: éŸ³å£°ç”Ÿæˆå¤±æ•— - éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
                )
                return None

            # speech_tokensãŒæ•°å€¤ã®ãƒªã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            try:
                speech_tokens = torch.tensor(speech_tokens, dtype=torch.long).cuda().unsqueeze(0).unsqueeze(0)
            except Exception as e:
                print(f"Error creating tensor from speech_tokens: {e}")
                print(f"speech_tokens content: {speech_tokens}")
                return None

            # éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’éŸ³å£°æ³¢å½¢ã«ãƒ‡ã‚³ãƒ¼ãƒ‰
            gen_wav = self.codec_model.decode_code(speech_tokens)

            # ç”Ÿæˆéƒ¨åˆ†ã®ã¿ãŒå¿…è¦ãªå ´åˆ
            if sample_audio_path and prompt_wav_len > 0:
                full_len = gen_wav.shape[-1]
                if full_len <= prompt_wav_len:
                    # ã“ã“ã§å…¨ã¦åˆ‡ã‚Šè½ã¨ã™ã¨ç©ºã«ãªã‚‹ã®ã§ã‚¬ãƒ¼ãƒ‰
                    print(
                        "Warning: Generated waveform length <= prompt length. Skipping trimming to avoid empty audio. / è­¦å‘Š: ç”Ÿæˆæ³¢å½¢é•·ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ä»¥ä¸‹ã®ãŸã‚ãƒˆãƒªãƒŸãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ç©ºéŸ³å£°ã‚’å›é¿"
                    )
                else:
                    gen_wav = gen_wav[:, :, prompt_wav_len:]

            print("Speech generation completed / éŸ³å£°ç”Ÿæˆå®Œäº†")
            return (16000, gen_wav[0, 0, :].cpu().numpy())

    def _generate_voices(self):
        """éŸ³å£°ã¨ãƒ†ã‚­ã‚¹ãƒˆã®çµ„ã¿åˆã‚ã›ã§éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹"""
        # ãƒãƒƒãƒç”Ÿæˆé–‹å§‹æ™‚ã«Dialogue.txtã‚’å†èª­ã¿è¾¼ã¿
        try:
            self._load_dialogue_txt()
            print(
                f"Reloaded {self.text_file_path} for batch generation - {len(self.text_lines)} text lines available / ãƒãƒƒãƒç”Ÿæˆç”¨ã«{self.text_file_path}å†èª­ã¿è¾¼ã¿ - {len(self.text_lines)}è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆãŒåˆ©ç”¨å¯èƒ½"
            )
        except Exception as e:
            print(
                f"Warning: Failed to reload {self.text_file_path}: {e} / è­¦å‘Š: {self.text_file_path}ã®å†èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}"
            )
            print("Using previously loaded text lines... / ä»¥å‰ã«èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’ä½¿ç”¨ã—ã¾ã™...")

        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã®è¨ˆç®—
        batch_size = len(self.audio_data) * len(self.text_lines)

        # ç·ç”Ÿæˆæ•°ã®è¨ˆç®—
        if self.batch_count == -1:
            print("Perpetual generation mode - generating until interrupted / æ°¸ç¶šç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ - ä¸­æ–­ã•ã‚Œã‚‹ã¾ã§ç”Ÿæˆ")
            total_generations = float("inf")
        else:
            total_generations = batch_size * self.batch_count

        generated_count = 0
        current_batch = 0

        # å…¨ä½“ã®ç”Ÿæˆé–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
        self.generation_start_time = time.time()

        try:
            # batch_count = -1ã®å ´åˆã¯æ°¸ç¶šç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨çµ„ã¿åˆã‚ã›ã‚’ç¹°ã‚Šè¿”ã—ï¼‰
            if self.batch_count == -1:
                while True:  # ç„¡é™ãƒ«ãƒ¼ãƒ—ã§å…¨çµ„ã¿åˆã‚ã›ã‚’ç¹°ã‚Šè¿”ã—
                    for j, text_data in enumerate(self.text_lines):
                        for i, audio_data in enumerate(self.audio_data):
                            print(
                                f"\nText: {text_data['text'][:50]}{'...' if len(text_data['text']) > 50 else ''} / ãƒ†ã‚­ã‚¹ãƒˆ: {text_data['text'][:50]}{'...' if len(text_data['text']) > 50 else ''}"
                            )
                            print(
                                f"Audio: {os.path.basename(audio_data['file'])} ({audio_data['duration']:.1f}s) / éŸ³å£°: {os.path.basename(audio_data['file'])} ({audio_data['duration']:.1f}ç§’)"
                            )

                            print(
                                f"\nGenerating perpetual mode - {generated_count + 1}/âˆ / æ°¸ç¶šãƒ¢ãƒ¼ãƒ‰ç”Ÿæˆä¸­ - {generated_count + 1}/âˆ"
                            )

                            # éŸ³å£°ã‚’ç”Ÿæˆ
                            if self._process_single_generation(
                                audio_data, text_data, generated_count, total_generations
                            ):
                                generated_count += 1
            else:
                # é€šå¸¸ã®ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰
                for j, text_data in enumerate(self.text_lines):
                    for i, audio_data in enumerate(self.audio_data):
                        print(
                            f"\nText: {text_data['text'][:50]}{'...' if len(text_data['text']) > 50 else ''} / ãƒ†ã‚­ã‚¹ãƒˆ: {text_data['text'][:50]}{'...' if len(text_data['text']) > 50 else ''}"
                        )
                        print(
                            f"Audio: {os.path.basename(audio_data['file'])} ({audio_data['duration']:.1f}s) / éŸ³å£°: {os.path.basename(audio_data['file'])} ({audio_data['duration']:.1f}ç§’)"
                        )

                        current_batch = 0
                        while current_batch < self.batch_count:
                            if generated_count >= total_generations:
                                break

                            print(
                                f"\nGenerating batch {current_batch + 1} - {generated_count + 1}/{total_generations} / ãƒãƒƒãƒ{current_batch + 1}ç”Ÿæˆä¸­ - {generated_count + 1}/{total_generations}"
                            )

                            # éŸ³å£°ã‚’ç”Ÿæˆ
                            if self._process_single_generation(
                                audio_data, text_data, generated_count, total_generations
                            ):
                                generated_count += 1

                            current_batch += 1

                        if generated_count >= total_generations:
                            break

                    if generated_count >= total_generations:
                        break

        except KeyboardInterrupt:
            if self.generation_start_time:
                interrupted_time = time.time() - self.generation_start_time
                print(
                    f"\nâ¹ï¸  Generation interrupted after {self._format_time(interrupted_time)} / {self._format_time(interrupted_time)}å¾Œã«ä¸­æ–­ã•ã‚Œã¾ã—ãŸ"
                )
            print(
                f"Generated {generated_count} files before interruption / ä¸­æ–­å‰ã«{generated_count}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ"
            )

        # ç·ç”Ÿæˆæ™‚é–“ã®è¡¨ç¤º
        if self.generation_start_time:
            total_generation_time = time.time() - self.generation_start_time
            print("\n" + "=" * 60)
            print("ğŸ‰ GENERATION SUMMARY / ç”Ÿæˆã‚µãƒãƒªãƒ¼")
            print("=" * 60)
            print(f"ğŸ“ Generated files: {generated_count} / ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {generated_count}å€‹")
            print(
                f"â±ï¸  Total generation time: {self._format_time(total_generation_time)} / ç·ç”Ÿæˆæ™‚é–“: {self._format_time(total_generation_time)}"
            )

            if self.generation_times:
                avg_time = sum(self.generation_times) / len(self.generation_times)
                min_time = min(self.generation_times)
                max_time = max(self.generation_times)
                print(f"ğŸ“Š Average time per file: {avg_time:.2f}s / 1ãƒ•ã‚¡ã‚¤ãƒ«å¹³å‡æ™‚é–“: {avg_time:.2f}ç§’")
                print(f"âš¡ Fastest generation: {min_time:.2f}s / æœ€é€Ÿç”Ÿæˆ: {min_time:.2f}ç§’")
                print(f"ğŸŒ Slowest generation: {max_time:.2f}s / æœ€é…ç”Ÿæˆ: {max_time:.2f}ç§’")
            print("=" * 60)

        print(
            f"\nVoice generation completed! Generated {generated_count} audio files / éŸ³å£°ç”Ÿæˆå®Œäº†ï¼{generated_count}å€‹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ"
        )

    def _run_server_mode(self):
        """ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œï¼ˆåå‰ä»˜ããƒ‘ã‚¤ãƒ—ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ï¼‰"""
        pipe_name = r"\\.\pipe\llasa_pipe"

        print(f"Starting named pipe server: {pipe_name}")
        print("Server mode ready. Waiting for connections... / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰æº–å‚™å®Œäº†ã€‚æ¥ç¶šå¾…æ©Ÿä¸­...")
        print("Note: Dialogue.txt is reloaded on each request / æ³¨æ„: å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§Dialogue.txtãŒå†èª­ã¿è¾¼ã¿ã•ã‚Œã¾ã™")
        print("=" * 60)

        generated_count = 0
        pipe = None

        try:
            while True:
                try:
                    # æ—¢å­˜ã®ãƒ‘ã‚¤ãƒ—ãŒã‚ã‚Œã°é–‰ã˜ã‚‹
                    if pipe is not None:
                        try:
                            win32file.CloseHandle(pipe)
                        except:
                            pass

                    # åå‰ä»˜ããƒ‘ã‚¤ãƒ—ã‚’ä½œæˆ
                    pipe = win32pipe.CreateNamedPipe(
                        pipe_name,
                        win32pipe.PIPE_ACCESS_DUPLEX,
                        win32pipe.PIPE_TYPE_MESSAGE | win32pipe.PIPE_READMODE_MESSAGE | win32pipe.PIPE_WAIT,
                        win32pipe.PIPE_UNLIMITED_INSTANCES,  # è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¨±å¯
                        65536,
                        65536,
                        0,
                        None,
                    )

                    if pipe == win32file.INVALID_HANDLE_VALUE:
                        print("Failed to create named pipe / åå‰ä»˜ããƒ‘ã‚¤ãƒ—ã®ä½œæˆã«å¤±æ•—")
                        break

                    print("Waiting for client connection... / ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šå¾…æ©Ÿä¸­...")

                    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æ¥ç¶šã‚’å¾…ã¤
                    win32pipe.ConnectNamedPipe(pipe, None)
                    print("Client connected / ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šå®Œäº†")

                    # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚‹
                    try:
                        result, data = win32file.ReadFile(pipe, 4096)
                        if result == 0:  # ERROR_SUCCESS
                            message = data.decode("utf-8").strip()
                            print(f"Received: {message}")

                            if message.lower() in ["quit", "exit", "q"]:
                                print("Server mode terminated. / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰çµ‚äº†ã€‚")
                                win32file.CloseHandle(pipe)
                                break

                            # å—ä¿¡ã—ãŸãƒ‘ã‚¹ã®å‡¦ç†ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰
                            paths = [path.strip() for path in message.split("\n") if path.strip()]

                            for input_path in paths:
                                # ãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèª
                                if not os.path.exists(input_path):
                                    print(
                                        f"Error: Path not found: {input_path} / ã‚¨ãƒ©ãƒ¼: ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}"
                                    )
                                    continue

                                # ãƒ‡ãƒ¼ãƒ¢ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ã¯å‡¦ç†å‰ã«Dialogue.txtã‚’å†èª­ã¿è¾¼ã¿
                                try:
                                    self._load_dialogue_txt()
                                    print(
                                        f"Reloaded {self.text_file_path} - {len(self.text_lines)} text lines available / {self.text_file_path}å†èª­ã¿è¾¼ã¿ - {len(self.text_lines)}è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆãŒåˆ©ç”¨å¯èƒ½"
                                    )
                                except Exception as e:
                                    print(
                                        f"Warning: Failed to reload {self.text_file_path}: {e} / è­¦å‘Š: {self.text_file_path}ã®å†èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}"
                                    )
                                    if not hasattr(self, "text_lines") or not self.text_lines:
                                        print(
                                            "âŒ No text lines available. Skipping... / ãƒ†ã‚­ã‚¹ãƒˆè¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™..."
                                        )
                                        continue

                                # å…¥åŠ›ãƒ‘ã‚¹ã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
                                collected_files = self._collect_audio_files_from_path(input_path)

                                if not collected_files:
                                    print(
                                        f"âŒ No audio files found in: {input_path} / éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}"
                                    )
                                    continue

                                # BatchGenerateã¨åŒæ§˜ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†
                                self.sound_files = collected_files
                                temp_audio_data = []

                                print(
                                    f"\nğŸ“ Processing {len(collected_files)} audio file(s) / {len(collected_files)}å€‹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­"
                                )

                                for audio_file in collected_files:
                                    try:
                                        audio_array, sample_rate = sf.read(audio_file)
                                        if len(audio_array.shape) > 1:
                                            audio_array = np.mean(audio_array, axis=1)

                                        duration = len(audio_array) / sample_rate
                                        temp_audio_data.append(
                                            {
                                                "file": audio_file,
                                                "array": audio_array,
                                                "sample_rate": sample_rate,
                                                "duration": duration,
                                            }
                                        )
                                        print(f"  âœ… {os.path.basename(audio_file)} ({duration:.1f}s)")
                                    except Exception as e:
                                        print(f"  âŒ Error loading {os.path.basename(audio_file)}: {e}")

                                if not temp_audio_data:
                                    print("âŒ No valid audio data processed / æœ‰åŠ¹ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå‡¦ç†ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                                    continue

                                # BatchGenerateã¨åŒã˜é †åºï¼šãƒ†ã‚­ã‚¹ãƒˆâ†’éŸ³å£°â†’ãƒãƒƒãƒã®é †
                                for j, text_data in enumerate(self.text_lines, 1):
                                    print(
                                        f"\nğŸ“ Text {j}/{len(self.text_lines)}: {text_data['text'][:30]}{'...' if len(text_data['text']) > 30 else ''}"
                                    )

                                    for i, audio_data in enumerate(temp_audio_data, 1):
                                        print(
                                            f"  ğŸµ Audio {i}/{len(temp_audio_data)}: {os.path.basename(audio_data['file'])} ({audio_data['duration']:.1f}s)"
                                        )

                                        # ãƒãƒƒãƒæ•°åˆ†ç”Ÿæˆï¼ˆã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã¯self.batch_countã‚’ä½¿ç”¨ï¼‰
                                        if hasattr(self, "batch_count") and self.batch_count == -1:
                                            # æ°¸ç¶šç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼šã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã‚‰åé›†ã•ã‚ŒãŸéŸ³å£°ã§æ°¸ç¶šç”Ÿæˆ
                                            print(
                                                f"    ğŸ” Perpetual mode started for this request / ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§æ°¸ç¶šç”Ÿæˆé–‹å§‹"
                                            )
                                            print(
                                                f"    âš ï¸  Use Ctrl+C to stop perpetual generation / æ°¸ç¶šç”Ÿæˆã‚’åœæ­¢ã™ã‚‹ã«ã¯Ctrl+Cã‚’ä½¿ç”¨"
                                            )

                                            perpetual_count = 0
                                            try:
                                                while True:  # æ°¸ç¶šãƒ«ãƒ¼ãƒ—
                                                    perpetual_count += 1
                                                    print(
                                                        f"    ğŸ”„ Perpetual batch {perpetual_count} - {generated_count + 1}/âˆ"
                                                    )

                                                    # éŸ³å£°ç”Ÿæˆã‚’å®Ÿè¡Œ
                                                    self._execute_server_generation(
                                                        audio_data, text_data, generated_count
                                                    )
                                                    generated_count += 1

                                            except KeyboardInterrupt:
                                                print(
                                                    f"\nâ¹ï¸  Perpetual generation interrupted after {perpetual_count} iterations"
                                                )
                                                print(f"æ°¸ç¶šç”ŸæˆãŒ{perpetual_count}å›ã®åå¾©å¾Œã«ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
                                                break
                                        else:
                                            # é€šå¸¸ã®ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰
                                            batch_count_for_server = (
                                                self.batch_count
                                                if hasattr(self, "batch_count") and self.batch_count > 0
                                                else 1
                                            )

                                            for batch_num in range(batch_count_for_server):
                                                if batch_count_for_server > 1:
                                                    print(f"    ğŸ”„ Batch {batch_num + 1}/{batch_count_for_server}")

                                                # éŸ³å£°ç”Ÿæˆã‚’å®Ÿè¡Œ
                                                self._execute_server_generation(audio_data, text_data, generated_count)
                                                generated_count += 1

                            # ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰å‡¦ç†å®Œäº†
                            print(
                                f"\nâœ… Server request completed: {generated_count} files generated / ã‚µãƒ¼ãƒãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†: {generated_count}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"
                            )

                            # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
                            try:
                                response = f"Processing completed. Generated {generated_count} files."
                                win32file.WriteFile(pipe, response.encode("utf-8"))
                                win32file.FlushFileBuffers(pipe)
                            except:
                                pass

                    except pywintypes.error as e:
                        print(f"Pipe read error: {e} / ãƒ‘ã‚¤ãƒ—èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")

                    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šã‚’åˆ‡æ–­
                    try:
                        win32pipe.DisconnectNamedPipe(pipe)
                    except:
                        pass

                except pywintypes.error as e:
                    print(f"Pipe connection error: {e} / ãƒ‘ã‚¤ãƒ—æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                    if "ã™ã¹ã¦ã®ãƒ‘ã‚¤ãƒ— ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒãƒ“ã‚¸ãƒ¼" in str(e):
                        print("Pipe busy, waiting and retrying... / ãƒ‘ã‚¤ãƒ—ãƒ“ã‚¸ãƒ¼ã€å¾…æ©Ÿå¾Œå†è©¦è¡Œ...")
                        time.sleep(1)
                        continue

        except KeyboardInterrupt:
            print("\nServer mode interrupted. / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ä¸­æ–­ã€‚")
        except Exception as e:
            print(f"Unexpected error: {e} / äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            # æœ€çµ‚çš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if pipe is not None:
                try:
                    win32pipe.DisconnectNamedPipe(pipe)
                    win32file.CloseHandle(pipe)
                except:
                    pass

        print(
            f"Server mode finished. Generated {generated_count} files. / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰çµ‚äº†ã€‚{generated_count}ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã€‚"
        )

    def run(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
        try:
            # å¼•æ•°ã‚’è§£æ
            self.parse_arguments()

            # åˆæœŸåŒ–é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨æ™‚é–“è¨ˆæ¸¬é–‹å§‹
            print("\n" + "=" * 60)
            print("INITIALIZING SYSTEM / ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­")
            print("=" * 60)
            print("Starting initialization... / åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...")

            init_start_time = time.time()

            # ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã«å‡¦ç†ã™ã‚‹ãŸã‚ï¼‰
            if self.server_mode:
                self.text_lines = []
                self.audio_data = []
                print("Server mode: Skipping file processing at startup (processed per request)")
                print("ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰: èµ·å‹•æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«å‡¦ç†ï¼‰")

                # ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ãƒãƒƒãƒæ•°ã®å…¥åŠ›å‡¦ç†ã¯å¿…è¦
                print("\n" + "=" * 80)
                print("BATCH SIZE AND GENERATION COUNT / ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ç”Ÿæˆæ•°")
                print("=" * 80)
                print("Server mode configuration / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰è¨­å®š")
                print("ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰è¨­å®š")

                # ãƒãƒƒãƒæ•°ã«å¿œã˜ãŸç·ç”Ÿæˆæ•°ã®è¡¨ç¤º
                if self.batch_count == -1:
                    print("\nGeneration mode: PERPETUAL / ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰: æ°¸ç¶šç”Ÿæˆ")
                    print("The system will generate continuously until stopped.")
                    print("ã‚·ã‚¹ãƒ†ãƒ ã¯åœæ­¢ã•ã‚Œã‚‹ã¾ã§ç¶™ç¶šçš„ã«ç”Ÿæˆã—ã¾ã™ã€‚")
                elif self.batch_count == 0:
                    # ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚å¯¾è©±çš„å…¥åŠ›ã‚’å¯èƒ½ã«ã™ã‚‹
                    print("\nGeneration mode: INTERACTIVE / ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰: å¯¾è©±çš„")
                    print("Server mode with interactive batch count / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã®å¯¾è©±çš„ãƒãƒƒãƒæ•°è¨­å®š")
                    try:
                        user_input = input(
                            "Enter the number of batches to generate / ç”Ÿæˆã™ã‚‹ãƒãƒƒãƒæ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: "
                        )
                        user_batches = int(user_input.strip())
                        if user_batches <= 0 and user_batches != -1:
                            raise ValueError("Batch count must be greater than 0 / ãƒãƒƒãƒæ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                        # å¯¾è©±ã§å…¥åŠ›ã•ã‚ŒãŸãƒãƒƒãƒæ•°ã‚’ä¿å­˜
                        self.batch_count = user_batches
                        if user_batches == -1:
                            print("Perpetual generation mode selected / æ°¸ç¶šç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
                            print("The system will generate continuously until stopped (Ctrl+C)")
                            print("ã‚·ã‚¹ãƒ†ãƒ ã¯åœæ­¢ã•ã‚Œã‚‹ã¾ã§ç¶™ç¶šçš„ã«ç”Ÿæˆã—ã¾ã™ (Ctrl+C)")
                        else:
                            print(f"Batch count set to: {user_batches} / ãƒãƒƒãƒæ•°ã‚’è¨­å®š: {user_batches}")
                    except ValueError as e:
                        if "invalid literal" in str(e):
                            raise ValueError(
                                "Invalid input. Please enter a valid number / ç„¡åŠ¹ãªå…¥åŠ›ã§ã™ã€‚æœ‰åŠ¹ãªæ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
                            )
                        else:
                            raise e
                else:
                    print(
                        f"\nGeneration mode: SPECIFIED ({self.batch_count} batches) / ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰: æŒ‡å®š ({self.batch_count}ãƒãƒƒãƒ)"
                    )
                print("=" * 80)
            else:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«åé›†ã¨ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
                # Dialogue.txtã‹ã‚‰linesã‚’é›†ã‚ã‚‹ã€‚ç©ºè¡Œã‚„èª­ã¿ä¸Šã’ã‚‰ã‚Œãªã„è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚
                self.text_lines = []
                self._load_dialogue_txt()

                # ã‚µã‚¦ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã—ã€Whisperã§è»¢å†™ã—ã¦ä½¿ç”¨ã™ã‚‹ã€‚
                # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä¾å­˜ã—ãªã„éŸ³å£°èªè­˜ãƒ™ãƒ¼ã‚¹ã®å‡¦ç†ã€‚
                self.audio_data = []
                self._collect_audio_data()

                # ã‚µãƒãƒªãƒ¼è¡¨ç¤ºã¨ç·ç”Ÿæˆæ•°ã®è¨ˆç®—
                self._display_generation_summary()

            print(f"Model: {self.model}")
            print(f"Quantization: {'Enabled' if self.quantization_enabled else 'Disabled'}")
            print(f"Server mode: {'Enabled' if self.server_mode else 'Disabled'}")
            print(f"Paths: {self.paths}")
            print(f"Batch count: {self.batch_count}")
            print(f"Text lines ready for processing: {len(self.text_lines)}")
            print(f"Valid audio data: {len(self.audio_data)}")

            # ã™ã¹ã¦ã®æƒ…å ±è¡¨ç¤ºå®Œäº†å¾Œã€ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
            print("\n" + "=" * 60)
            print("LOADING MODELS / ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
            print("=" * 60)
            self._load_models()

            # åˆæœŸåŒ–å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨æ‰€è¦æ™‚é–“è¡¨ç¤º
            init_end_time = time.time()
            init_duration = init_end_time - init_start_time
            print("\n" + "=" * 60)
            print("INITIALIZATION COMPLETE / åˆæœŸåŒ–å®Œäº†")
            print("=" * 60)
            print(
                f"Initialization completed in {init_duration:.2f} seconds / åˆæœŸåŒ–ãŒ{init_duration:.2f}ç§’ã§å®Œäº†ã—ã¾ã—ãŸ"
            )
            print("Ready to proceed! / å‡¦ç†é–‹å§‹æº–å‚™å®Œäº†ï¼")

            if self.server_mode:
                print("\n" + "=" * 60)
                print("STARTING SERVER MODE / ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
                print("=" * 60)
                self._run_server_mode()
            else:
                print("\n" + "=" * 60)
                print("STARTING VOICE GENERATION / éŸ³å£°ç”Ÿæˆé–‹å§‹")
                print("=" * 60)
                self._generate_voices()

        except ValueError as e:
            print(f"\nâŒ Error: {e}")
            input("Press Enter to exit / Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦çµ‚äº†...")
            return 1  # ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã™
        except Exception as e:
            print(f"\nâŒ Unexpected error: {e} / äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            input("Press Enter to exit / Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦çµ‚äº†...")
            return 1

        return 0  # æ­£å¸¸çµ‚äº†


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    llasa = Llasa()
    exit_code = llasa.run()
    exit(exit_code)


if __name__ == "__main__":
    main()
